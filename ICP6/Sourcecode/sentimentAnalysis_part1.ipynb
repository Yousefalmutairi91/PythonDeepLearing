{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimentAnalysis_part1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyz8aNi4enAR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.callbacks import TensorBoard\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7dpWvLseseo"
      },
      "source": [
        "data = pd.read_csv('/content/Sentiment.csv')\n",
        "data = data[['text', 'sentiment']]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "VRaJJcCMex5C",
        "outputId": "c09db146-00a4-485b-9509-d2f628e139e9"
      },
      "source": [
        "# all string to lowercase Read more about lambda() \"https://realpython.com/python-lambda/\"\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "# using regular expression preprocess the text by removing everything that is not [a-zA-z0-9\\s]\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n",
        "\n",
        "print(data[data['sentiment'] == 'Positive'].size)\n",
        "print(data[data['sentiment'] == 'Negative'].size)\n",
        "print(data[data['sentiment'] == 'Neutral'].size)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4472\n",
            "16986\n",
            "6284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rt nancyleegrahn how did everyone feel about t...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rt scottwalker didnt catch the full gopdebate ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rt tjmshow no mention of tamir rice and the go...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rt robgeorge that carly fiorina is trending  h...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt danscavino gopdebate w realdonaldtrump deli...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text sentiment\n",
              "0  rt nancyleegrahn how did everyone feel about t...   Neutral\n",
              "1  rt scottwalker didnt catch the full gopdebate ...  Positive\n",
              "2  rt tjmshow no mention of tamir rice and the go...   Neutral\n",
              "3  rt robgeorge that carly fiorina is trending  h...  Positive\n",
              "4  rt danscavino gopdebate w realdonaldtrump deli...  Positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjMyvBn2e2sm",
        "outputId": "64bfaabf-0173-4d8a-e737-1abb03450e08"
      },
      "source": [
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')\n",
        "\n",
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "X = pad_sequences(X, maxlen=28)\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "#build the model\n",
        "batch_size = 128\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "tb = TensorBoard(log_dir=\"logs/{}\", histogram_freq=0, write_graph=True, write_images=True)\n",
        "fmodel = model.fit(X_train, Y_train, epochs=5, batch_size=batch_size, verbose=2, callbacks=[tb])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "82/82 - 28s - loss: 0.8848 - accuracy: 0.6182\n",
            "Epoch 2/5\n",
            "82/82 - 24s - loss: 0.7288 - accuracy: 0.6861\n",
            "Epoch 3/5\n",
            "82/82 - 24s - loss: 0.6591 - accuracy: 0.7178\n",
            "Epoch 4/5\n",
            "82/82 - 24s - loss: 0.6223 - accuracy: 0.7357\n",
            "Epoch 5/5\n",
            "82/82 - 24s - loss: 0.5945 - accuracy: 0.7506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0-6qJd9fCum"
      },
      "source": [
        "#save the model\n",
        "model.save('/content/saved_model.h5')\n",
        "m = load_model('/content/saved_model.h5')\n",
        "\n",
        "text = [['A lot of good things are happening. We are respected again throughout the world, and thats a great thing. @realDonaldTrump']]\n",
        "df = pd.DataFrame(text, index=range(0, 1, 1), columns=list('t'))\n",
        "df['t'] = df['t'].apply(lambda x: x.lower())\n",
        "df['t'] = df['t'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOaZt9fjkxiH"
      },
      "source": [
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(df['t'].values)\n",
        "X = tokenizer.texts_to_sequences(df['t'].values)\n",
        "# Pads sequences to the same length.\n",
        "X = pad_sequences(X, maxlen=28)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oGbUJ3Mjiph",
        "outputId": "e0e12352-b6b2-4551-df68-bb66fff629fa"
      },
      "source": [
        "#predect it\n",
        "output = m.predict(X)\n",
        "print('Output:', output)\n",
        "print(numpy.where(max(output[0])), \":\", (max(output[0])))\n",
        "print(numpy.argmax(output))\n",
        "print(model.summary())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output: [[0.82746    0.05978538 0.11275464]]\n",
            "(array([0]),) : 0.82746\n",
            "0\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 28, 128)           256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 28, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 196)               254800    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 591       \n",
            "=================================================================\n",
            "Total params: 511,391\n",
            "Trainable params: 511,391\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}